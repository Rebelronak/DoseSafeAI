"""
Custom OCR Model Training for Medical Documents
Train a specialized OCR model for prescription images and medical documents
Using scikit-learn and XGBoost (Python 3.13 compatible)
"""

import numpy as np
import cv2
import os
from PIL import Image
import json
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
import joblib
import matplotlib.pyplot as plt
from fuzzywuzzy import fuzz
import pandas as pd

class MedicalTextClassifier:
    """
    ML-powered medicine name extractor and text classifier
    Uses scikit-learn and XGBoost for medical document analysis
    """
    
    def __init__(self, model_name="medical_text_classifier_v1"):
        self.model_name = model_name
        self.medicine_classifier = None
        self.text_vectorizer = None
        self.medicine_database = []
        self.interaction_classifier = None
        self.known_medicines = set()
        
    def load_medicine_database(self, medicine_file="data/medicines.json"):
        """Load comprehensive medicine database for training"""
        
        print("üìö Loading medicine database...")
        
        # Create comprehensive medicine list if file doesn't exist
        if not os.path.exists(medicine_file):
            self.medicine_database = self._create_default_medicine_database()
            os.makedirs(os.path.dirname(medicine_file), exist_ok=True)
            with open(medicine_file, 'w') as f:
                json.dump(self.medicine_database, f, indent=2)
        else:
            with open(medicine_file, 'r') as f:
                self.medicine_database = json.load(f)
        
        # Build known medicines set
        for med in self.medicine_database:
            self.known_medicines.add(med['name'].lower())
            if 'aliases' in med:
                for alias in med['aliases']:
                    self.known_medicines.add(alias.lower())
        
        print(f"‚úÖ Loaded {len(self.medicine_database)} medicines")
        print(f"‚úÖ Total medicine variants: {len(self.known_medicines)}")
        
    def _create_default_medicine_database(self):
        """Create comprehensive medicine database"""
        
        return [
            {
                "name": "Aspirin",
                "aliases": ["acetylsalicylic acid", "ASA", "aspirin"],
                "category": "NSAID",
                "common_doses": ["81mg", "325mg", "500mg"],
                "interactions": ["warfarin", "ibuprofen", "alcohol"]
            },
            {
                "name": "Warfarin",
                "aliases": ["coumadin", "warfarin sodium"],
                "category": "Anticoagulant",
                "common_doses": ["1mg", "2mg", "5mg", "10mg"],
                "interactions": ["aspirin", "ibuprofen", "vitamin K"]
            },
            {
                "name": "Hydroxyzine",
                "aliases": ["atarax", "vistaril", "hydroxyzine hcl"],
                "category": "Antihistamine",
                "common_doses": ["10mg", "25mg", "50mg"],
                "interactions": ["alcohol", "sedatives"]
            },
            {
                "name": "Metoprolol",
                "aliases": ["lopressor", "toprol xl", "metoprolol tartrate"],
                "category": "Beta Blocker",
                "common_doses": ["25mg", "50mg", "100mg"],
                "interactions": ["insulin", "epinephrine"]
            },
            {
                "name": "Lorazepam",
                "aliases": ["ativan", "lorazepam"],
                "category": "Benzodiazepine",
                "common_doses": ["0.5mg", "1mg", "2mg"],
                "interactions": ["alcohol", "opioids", "sedatives"]
            },
            {
                "name": "Lisinopril",
                "aliases": ["prinivil", "zestril"],
                "category": "ACE Inhibitor",
                "common_doses": ["2.5mg", "5mg", "10mg", "20mg"],
                "interactions": ["potassium", "lithium"]
            },
            {
                "name": "Ibuprofen",
                "aliases": ["advil", "motrin", "ibuprofen"],
                "category": "NSAID",
                "common_doses": ["200mg", "400mg", "600mg", "800mg"],
                "interactions": ["warfarin", "aspirin", "lithium"]
            },
            {
                "name": "Acetaminophen",
                "aliases": ["tylenol", "paracetamol"],
                "category": "Analgesic",
                "common_doses": ["325mg", "500mg", "650mg"],
                "interactions": ["alcohol", "warfarin"]
            }
        ]
    
    def extract_image_features(self, image_path):
        """Extract features from medical document images using OpenCV"""
        
        # Read image
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            return None
            
        # Preprocess image
        img = cv2.resize(img, (256, 64))
        
        # Feature extraction
        features = []
        
        # 1. Histogram features
        hist = cv2.calcHist([img], [0], None, [256], [0, 256])
        features.extend(hist.flatten())
        
        # 2. Edge features
        edges = cv2.Canny(img, 50, 150)
        edge_density = np.sum(edges) / (edges.shape[0] * edges.shape[1])
        features.append(edge_density)
        
        # 3. Texture features (Local Binary Pattern approximation)
        # Simple texture measure
        laplacian = cv2.Laplacian(img, cv2.CV_64F)
        texture_var = laplacian.var()
        features.append(texture_var)
        
        # 4. Image statistics
        features.extend([img.mean(), img.std(), img.min(), img.max()])
        
        return np.array(features)
    
    def prepare_text_training_data(self):
        """Prepare training data for medicine name classification"""
        
        print("üî§ Preparing text classification training data...")
        
        # Generate training samples
        positive_samples = []
        negative_samples = []
        
        # Positive samples (actual medicine names)
        for med in self.medicine_database:
            positive_samples.append(med['name'])
            if 'aliases' in med:
                positive_samples.extend(med['aliases'])
        
        # Generate variations and misspellings
        variations = []
        for med_name in positive_samples:
            # Add with different cases
            variations.extend([
                med_name.upper(),
                med_name.lower(),
                med_name.title(),
                med_name + "variant22",  # Test variants
                med_name + "variant21"
            ])
        
        positive_samples.extend(variations)
        
        # Negative samples (non-medicine words)
        negative_words = [
            "patient", "age", "doctor", "hospital", "clinic", "prescription",
            "daily", "twice", "morning", "evening", "tablet", "capsule",
            "before", "after", "meals", "food", "water", "instructions",
            "dose", "dosage", "frequency", "continue", "stop", "start",
            "monday", "tuesday", "wednesday", "thursday", "friday",
            "january", "february", "march", "april", "may", "june"
        ]
        
        negative_samples.extend(negative_words * 3)  # Multiply for balance
        
        # Create labels
        X_text = positive_samples + negative_samples
        y_labels = [1] * len(positive_samples) + [0] * len(negative_samples)
        
        print(f"‚úÖ Created {len(positive_samples)} positive samples")
        print(f"‚úÖ Created {len(negative_samples)} negative samples")
        
        return X_text, y_labels
    
    def train_medicine_classifier(self):
        """Train ML model to classify medicine names"""
        
        print("üöÄ Training medicine name classifier...")
        
        # Prepare training data
        X_text, y_labels = self.prepare_text_training_data()
        
        # Create text features using TF-IDF
        self.text_vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 3),
            analyzer='char',  # Character-level for better medicine name matching
            lowercase=True
        )
        
        X_features = self.text_vectorizer.fit_transform(X_text)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_features, y_labels, test_size=0.2, random_state=42
        )
        
        # Train XGBoost classifier
        self.medicine_classifier = xgb.XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            eval_metric='logloss'
        )
        
        self.medicine_classifier.fit(X_train, y_train)
        
        # Evaluate
        y_pred = self.medicine_classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"‚úÖ Medicine classifier accuracy: {accuracy:.3f}")
        print(f"üìä Classification report:")
        print(classification_report(y_test, y_pred))
        
        return accuracy
    
    def extract_medicines_from_text(self, text):
        """Extract medicine names from text using trained ML model"""
        
        if not self.medicine_classifier or not self.text_vectorizer:
            print("‚ö†Ô∏è Model not trained. Using fallback extraction.")
            return self._fallback_medicine_extraction(text)
        
        # Tokenize text into potential medicine candidates
        words = text.lower().replace('\n', ' ').split()
        
        extracted_medicines = []
        
        for word in words:
            # Clean word
            clean_word = ''.join(c for c in word if c.isalnum())
            if len(clean_word) < 3:  # Skip very short words
                continue
            
            # Vectorize word
            word_features = self.text_vectorizer.transform([clean_word])
            
            # Predict if it's a medicine
            prediction = self.medicine_classifier.predict(word_features)[0]
            confidence = self.medicine_classifier.predict_proba(word_features)[0][1]
            
            if prediction == 1 and confidence > 0.7:  # High confidence threshold
                # Clean up medicine name (remove variants)
                clean_medicine = self._clean_medicine_name(clean_word)
                
                if clean_medicine not in [m['name'] for m in extracted_medicines]:
                    extracted_medicines.append({
                        'name': clean_medicine,
                        'dose': 'Not specified',
                        'frequency': 'As prescribed',
                        'confidence': float(confidence)
                    })
        
        print(f"üîç ML extraction found {len(extracted_medicines)} medicines")
        for med in extracted_medicines:
            print(f"  - {med['name']} (confidence: {med['confidence']:.3f})")
        
        return extracted_medicines
    
    def _clean_medicine_name(self, raw_name):
        """Clean medicine name by removing variants and normalizing"""
        
        # Remove common variants
        clean_name = raw_name.lower()
        clean_name = clean_name.replace('variant22', '').replace('variant21', '')
        clean_name = clean_name.replace('hcl', '').replace('sodium', '')
        
        # Find best match in known medicines
        best_match = None
        best_score = 0
        
        for known_med in self.known_medicines:
            score = fuzz.ratio(clean_name, known_med)
            if score > best_score and score > 80:  # 80% similarity threshold
                best_score = score
                best_match = known_med
        
        if best_match:
            # Return properly capitalized version
            for med in self.medicine_database:
                if med['name'].lower() == best_match or best_match in [a.lower() for a in med.get('aliases', [])]:
                    return med['name']
        
        return clean_name.title()
    
    def _fallback_medicine_extraction(self, text):
        """Fallback extraction using fuzzy matching"""
        
        words = text.lower().replace('\n', ' ').split()
        extracted_medicines = []
        
        for word in words:
            clean_word = ''.join(c for c in word if c.isalnum())
            
            for known_med in self.known_medicines:
                if fuzz.ratio(clean_word, known_med) > 85:
                    clean_name = self._clean_medicine_name(clean_word)
                    if clean_name not in [m['name'] for m in extracted_medicines]:
                        extracted_medicines.append({
                            'name': clean_name,
                            'dose': 'Not specified',
                            'frequency': 'As prescribed',
                            'confidence': 0.8
                        })
                    break
        
        return extracted_medicines
    
    def save_model(self, save_dir="models"):
        """Save trained models"""
        
        os.makedirs(save_dir, exist_ok=True)
        
        if self.medicine_classifier:
            # Save XGBoost model
            model_path = os.path.join(save_dir, f"{self.model_name}_classifier.json")
            self.medicine_classifier.save_model(model_path)
            
            # Save vectorizer
            vectorizer_path = os.path.join(save_dir, f"{self.model_name}_vectorizer.joblib")
            joblib.dump(self.text_vectorizer, vectorizer_path)
            
            # Save medicine database
            db_path = os.path.join(save_dir, f"{self.model_name}_medicine_db.json")
            with open(db_path, 'w') as f:
                json.dump(self.medicine_database, f, indent=2)
            
            print(f"üíæ Model saved to {model_path}")
            print(f"üíæ Vectorizer saved to {vectorizer_path}")
            print(f"üíæ Medicine database saved to {db_path}")
    
    def load_model(self, save_dir="models"):
        """Load trained models"""
        
        try:
            # Load XGBoost model
            model_path = os.path.join(save_dir, f"{self.model_name}_classifier.json")
            self.medicine_classifier = xgb.XGBClassifier()
            self.medicine_classifier.load_model(model_path)
            
            # Load vectorizer
            vectorizer_path = os.path.join(save_dir, f"{self.model_name}_vectorizer.joblib")
            self.text_vectorizer = joblib.load(vectorizer_path)
            
            # Load medicine database
            db_path = os.path.join(save_dir, f"{self.model_name}_medicine_db.json")
            with open(db_path, 'r') as f:
                self.medicine_database = json.load(f)
            
            # Rebuild known medicines set
            self.known_medicines = set()
            for med in self.medicine_database:
                self.known_medicines.add(med['name'].lower())
                if 'aliases' in med:
                    for alias in med['aliases']:
                        self.known_medicines.add(alias.lower())
            
            print(f"‚úÖ Model loaded from {model_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Failed to load model: {e}")
            return False

def create_sample_training_data():
    """
    Create sample training data structure for medical text classification
    """
    
    sample_prescriptions = [
        "Patient: John Doe Age: 45\nMedicines:\nAspirin 81mg once daily\nMetoprolol 50mg twice daily\nLisinopril 10mg once daily",
        "Patient: Jane Smith Age: 62\nMedicines:\nWarfarin 5mg daily\nAtorvastatin 20mg once daily\nOmeprazole 20mg before meals",
        "Patient: Bob Wilson Age: 38\nMedicines:\nIbuprofen 400mg every 8 hours\nAcetaminophen 500mg as needed\nAlbuterol inhaler 2 puffs twice daily",
        "Patient: Alice Brown Age: 70\nMedicines:\nHydroxyzineVariant22 25mg\nLorazepamVariant21 0.5mg\nAspirin 81mg daily",
        "Patient: Charlie Davis Age: 55\nMedicines:\nWarfarin 2mg\nAspirin 81mg\nHydroxyzine 10mg as needed"
    ]
    
    # Save sample data
    with open('sample_prescriptions.json', 'w') as f:
        json.dump(sample_prescriptions, f, indent=2)
    
    print("üìù Sample prescription data created in 'sample_prescriptions.json'")

def test_ml_extraction():
    """Test the ML medicine extraction on sample data"""
    
    print("üß™ Testing ML Medicine Extraction...")
    print("=" * 50)
    
    # Initialize classifier
    classifier = MedicalTextClassifier("dosesafe_ml_v1")
    
    # Load medicine database
    classifier.load_medicine_database()
    
    # Train the model
    accuracy = classifier.train_medicine_classifier()
    
    # Test on sample texts
    test_texts = [
        "Patient: Age 70 (elderly)\nMedicines:\nAspirin\nWarfarin\nHydroxyzine",
        "HydroxyzineVariant22 25mg twice daily",
        "LorazepamVariant21 0.5mg as needed for anxiety",
        "Metoprolol 50mg BID, Aspirin 81mg daily"
    ]
    
    print("\nÔøΩ Testing medicine extraction:")
    for i, text in enumerate(test_texts, 1):
        print(f"\nTest {i}: {text[:50]}...")
        medicines = classifier.extract_medicines_from_text(text)
        print(f"Extracted medicines:")
        for med in medicines:
            print(f"  - {med['name']} (confidence: {med.get('confidence', 'N/A')})")
    
    # Save the trained model
    classifier.save_model()
    
    return classifier

if __name__ == "__main__":
    # Example usage
    print("üè• Medical ML Trainer for DoseSafe-AI")
    print("=" * 50)
    
    # Create sample data structure
    create_sample_training_data()
    
    # Test ML extraction
    classifier = test_ml_extraction()
    
    print("\nüìã ML Training Complete!")
    print("‚úÖ Medicine classifier trained and saved")
    print("‚úÖ Ready for integration with OCR pipeline")
    print("\nüöÄ Next steps:")
    print("1. Integrate trained model with ai_only_ocr.py")
    print("2. Add more training data for better accuracy")
    print("3. Fine-tune model parameters")
    print("4. Test on real prescription images")
